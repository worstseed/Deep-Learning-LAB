{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main function\n",
      "... read data\n"
     ]
    }
   ],
   "source": [
    "# %load train_agent.py\n",
    "from __future__ import print_function\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import Model\n",
    "from utils import *\n",
    "from tensorboard_evaluation import Evaluation\n",
    "import tensorflow as tf\n",
    "\n",
    "def read_data(datasets_dir=\"./data\", frac = 0.1):\n",
    "    \"\"\"\n",
    "    This method reads the states and actions recorded in drive_manually.py \n",
    "    and splits it into training/ validation set.\n",
    "    \"\"\"\n",
    "    print(\"... read data\")\n",
    "    data_file = os.path.join(datasets_dir, 'data.pkl.gzip')\n",
    "  \n",
    "    f = gzip.open(data_file,'rb')\n",
    "    data = pickle.load(f)\n",
    "\n",
    "    # get images as features and actions as targets\n",
    "    X = np.array(data[\"state\"]).astype('float32')\n",
    "    y = np.array(data[\"action\"]).astype('float32')\n",
    "\n",
    "    # split data into training and validation set\n",
    "    n_samples = len(data[\"state\"])\n",
    "    X_train, y_train = X[:int((1-frac) * n_samples)], y[:int((1-frac) * n_samples)]\n",
    "    X_valid, y_valid = X[int((1-frac) * n_samples):], y[int((1-frac) * n_samples):]\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "\n",
    "def data_augmentation(X_train, y_train_id):\n",
    "    # left:\n",
    "    left_indices = (y_train_id == LEFT)\n",
    "    # right:\n",
    "    right_indices = (y_train_id == RIGHT)\n",
    "    X_new_left_data = np.flip(X_train[left_indices], axis=2)\n",
    "    X_new_right_data = np.flip(X_train[right_indices], axis=2)\n",
    "    y_new_left_data = np.zeros((X_new_left_data.shape[0])) + RIGHT\n",
    "    y_new_right_data = np.zeros((X_new_right_data.shape[0])) + LEFT\n",
    "    X_train_n = np.concatenate((X_train, X_new_left_data, X_new_right_data), axis=0)\n",
    "    y_train_id_n = np.concatenate((y_train_id, y_new_left_data, y_new_right_data), axis=0)\n",
    "    \n",
    "    return X_train_n, y_train_id_n\n",
    "\n",
    "def id_to_action(labels_id):\n",
    "    classes = 3\n",
    "    labels_action = np.zeros((labels_id.shape[0], classes))\n",
    "    labels_action[labels_id==LEFT] = [-1.0, 0.0, 0.0]\n",
    "    labels_action[labels_id==RIGHT] = [1.0, 0.0, 0.0]\n",
    "    labels_action[labels_id==STRAIGHT] = [0.0, 0.0, 0.0]\n",
    "    labels_action[labels_id==ACCELERATE] = [0.0, 1.0, 0.0]\n",
    "    labels_action[labels_id==BRAKE] = [0.0, 0.0, 0.2]\n",
    "    return labels_action\n",
    "\n",
    "def uniform_sampling(X_train, y_train_id, num_samples):\n",
    "    # return the indices of sampled data\n",
    "    n = X_train.shape[0]\n",
    "    weights = np.zeros(n)\n",
    "    left_indices = y_train_id == LEFT\n",
    "    weights[y_train_id == LEFT] = n / np.sum(left_indices)\n",
    "    right_indices = y_train_id == RIGHT\n",
    "    weights[y_train_id == RIGHT] = n / np.sum(right_indices)\n",
    "    straight_indices = y_train_id == STRAIGHT\n",
    "    weights[y_train_id == STRAIGHT] = n / np.sum(straight_indices)\n",
    "    acce_indices = y_train_id == ACCELERATE\n",
    "    weights[y_train_id == ACCELERATE] = n / np.sum(acce_indices)\n",
    "    brake_indices = y_train_id == BRAKE\n",
    "    weights[y_train_id == BRAKE] = n / np.sum(brake_indices)\n",
    "    weights = weights / np.sum(weights)\n",
    "    samples_indices = np.random.choice(np.arange(n), num_samples, replace = False, p = weights)\n",
    "    \n",
    "    return samples_indices\n",
    "\n",
    "    # sample_minibatch(X_train, y_train, batch_index, history_length)\n",
    "def sample_minibatch(X, y, batch_index history_length=1):\n",
    "    # get small batch\n",
    "    batch_size = batch_index.shape[0]\n",
    "    X_batch = np.zeros((batch_size, X.shape[1], X.shape[2], history_length))\n",
    "    for i in range(history_length):\n",
    "        X_batch[:,:,:,i] = X[batch_index+i]\n",
    "        # X_batch[:,:,:,i] = X[i+b*batch_size:i+(b+1)*batch_size]\n",
    "    y_batch = y[history_length-1+b*batch_size:history_length-1+(b+1)*batch_size]\n",
    "    # shuffle data slightly (because it's in the batch)\n",
    "    # index = np.random.permutation(batch_size)\n",
    "    # X_batch, y_batch = X_train[b*batch_size:(b+1)*batch_size], y_train[b*batch_size:(b+1)*batch_size]\n",
    "    # X_batch, y_batch = X_batch[index], y_batch[index]\n",
    "    return X_batch, y_batch\n",
    "\n",
    "\n",
    "def preprocessing(X_train, y_train, X_valid, y_valid, history_length=1):\n",
    "\n",
    "    # TODO: preprocess your data here.\n",
    "    # 1. convert the images in X_train/X_valid to gray scale. If you use rgb2gray() from utils.py, the output shape (96, 96, 1)\n",
    "    # 2. you can either train your model with continous actions (as you get them from read_data) using regression\n",
    "    #    or you discretize the action space using action_to_id() from utils.py. If you discretize them, you'll maybe find one_hot() \n",
    "    #    useful and you may want to return X_train_unhot ... as well.\n",
    "    X_train = rgb2gray(X_train)\n",
    "    X_valid = rgb2gray(X_valid)\n",
    "    # history:\n",
    "    \n",
    "    # X_train_history = np.zeros((X_train.shape[0]-history_length+1, history_length, X_train.shape[1], X_train.shape[2]))\n",
    "    # for i in range(X_train_history.shape[0]):\n",
    "    #     X_train_history[i] = X_train[i:i+history_length,:,:]\n",
    "    # X_train_history = X_train_history.transpose(0,2,3,1)\n",
    "    \n",
    "    # X_valid_history = np.zeros((X_valid.shape[0]-history_length+1, history_length, X_valid.shape[1], X_valid.shape[2]))\n",
    "    # for i in range(X_valid_history.shape[0]):\n",
    "    #     X_valid_history[i] = X_valid[i:i+history_length,:,:]\n",
    "    # X_valid_history = X_valid_history.transpose(0,2,3,1)\n",
    "    \n",
    "    # y_valid_history = y_valid[history_length-1:]\n",
    "    # discretize actions\n",
    "    # y_train_id = np.zeros(y_train.shape[0]-history_length+1)\n",
    "    # y_valid_id = np.zeros(y_valid.shape[0]-history_length+1)\n",
    "    \n",
    "    # data augmentation\n",
    "    #for i in range(y_train.shape[0]-history_length+1):\n",
    "    for i in range(y_train.shape[0]):\n",
    "        y_train_id[i] = action_to_id(y_train[i])\n",
    "    \n",
    "    # X_train_n, y_train_id_n = data_augmentation(X_train, y_train_id)\n",
    "    # X_train_sampled, y_train_id_sampled = uniform_sampling(X_train, y_train_id, num_samples=12000)\n",
    "\n",
    "    # y_train_action = id_to_action(y_train_id_sampled)\n",
    "    # History:\n",
    "    # At first you should only use the current image as input to your network to learn the next action. Then the input states\n",
    "    # have shape (96, 96,1). Later, add a history of the last N images to your state so that a state has shape (96, 96, N).\n",
    "    \n",
    "    # return X_train_sampled, y_train_action, X_valid_history, y_valid_history\n",
    "    return X_train, y_train_id, X_valid, y_valid\n",
    "    # return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "def train_model(X_train, y_train, X_valid, y_valid, epochs, batch_size, lr, history_length=1, model_dir=\"./models\", tensorboard_dir=\"./tensorboard\"):\n",
    "    \n",
    "    # create result and model folders\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)  \n",
    " \n",
    "    print(\"... train model\")\n",
    "\n",
    "\n",
    "    # TODO: specify your neural network in model.py \n",
    "    agent = Model(learning_rate=lr, history_length=history_length)\n",
    "    init = tf.global_variables_initializer()\n",
    "    agent.sess.run(init)\n",
    "    tensorboard_eval = Evaluation(tensorboard_dir)\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # calculate the accuracy\n",
    "    # y_pred = tf.argmax(agent.output, 1)\n",
    "    # tf.add_to_collection('pred_network', y_pred)\n",
    "    # correct_pred = tf.equal(agent.y_pred, tf.argmax(agent.y_label, 1))\n",
    "    # calculate train and valid accuracy\n",
    "    # accuracy = tf.reduce_mean(tf.cast(correct_pred, \"float\"))\n",
    "    # init all variables\n",
    "    \n",
    "    # TODO: implement the training\n",
    "    # \n",
    "    # 1. write a method sample_minibatch and perform an update step\n",
    "    # 2. compute training/ validation accuracy and loss for the batch and visualize them with tensorboard. You can watch the progress of\n",
    "    #    your training in your web browser\n",
    "    \n",
    "    offset = history_length - 1\n",
    "    num_samples = 12000\n",
    "\n",
    "    # training loop\n",
    "    train_cost = np.zeros((epochs))\n",
    "    # train_accuracy = np.zeros((epochs))\n",
    "    valid_cost = np.zeros((epochs))\n",
    "    for epoch in range(epochs):\n",
    "        # shuffle the data set\n",
    "        # index = np.random.permutation(X_train.shape[0])\n",
    "        index = uniform_sampling(X_train[offset:], y_train[offset:])\n",
    "        total_batch_num = (num_samples - history_length + 1) // batch_size;\n",
    "        total_batch_num_valid = (X_valid.shape[0] - history_length + 1)// batch_size;\n",
    "        \n",
    "        # X_train_sampled, y_train_sampled = X_train[index], y_train[index]\n",
    "        \n",
    "        for b in range(total_batch_num):\n",
    "            # select the batch data\n",
    "            batch_index = index[b*batch_size:(b+1)*batch_size]\n",
    "            X_batch, y_batch = sample_minibatch(X_train, y_train, batch_index, history_length)\n",
    "            # compute the cost\n",
    "            _ , temp_cost = agent.sess.run([agent.optimizer, agent.cost], feed_dict={agent.x_input:X_batch, agent.y_label:y_batch})\n",
    "\n",
    "        # training cost\n",
    "        for b in range(total_batch_num):\n",
    "            batch_index = index[b*batch_size:(b+1)*batch_size]\n",
    "            X_batch, y_batch = sample_minibatch(X_train, y_train, batch_index, history_length)\n",
    "            train_cost[epoch] += agent.sess.run(agent.cost, feed_dict={agent.x_input: X_batch, agent.y_label: y_batch})\n",
    "\n",
    "        # validation cost\n",
    "        for b in range(total_batch_num_valid):\n",
    "            batch_index = np.arange(b*batch_size:(b+1)*batch_size)\n",
    "            X_valid_batch, y_valid_batch = sample_minibatch(X_valid, y_valid, batch_index, history_length)\n",
    "            valid_cost[epoch] += agent.sess.run(agent.cost, feed_dict={agent.x_input:X_valid_batch, agent.y_label:y_valid_batch})\n",
    "        train_cost[epoch] = train_cost[epoch] / total_batch_num\n",
    "        valid_cost[epoch] = valid_cost[epoch] / total_batch_num_valid\n",
    "        print(\"[%d/%d]: train_cost: %.4f, valid_cost: %.4f\" %(epoch+1, epochs, train_cost[epoch], valid_cost[epoch]))\n",
    "        eval_dict = {\"train\":train_cost[epoch], \"valid\":valid_cost[epoch]}\n",
    "        tensorboard_eval.write_episode_data(epoch, eval_dict)\n",
    "      \n",
    "    # TODO: save your agent\n",
    "    agent.save(os.path.join(model_dir, \"agent.ckpt\"))\n",
    "    print(model_dir)\n",
    "    print(\"Model saved in file: %s\" % model_dir)\n",
    "    agent.sess.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"main function\")\n",
    "    # read data    \n",
    "    X_train, y_train, X_valid, y_valid = read_data(\"./data\")\n",
    "    history_length = 5\n",
    "    n = X_train.shape[0]\n",
    "    # preprocess data\n",
    "    X_train, y_train_id, X_valid, y_valid = preprocessing(X_train, y_train, X_valid, y_valid)\n",
    "    # train model (you can change the parameters!)\n",
    "    # train_model(X_train, y_train, X_valid, y_valid, history_length=history_length, epochs=20, batch_size=64, lr=0.0004)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_minibatch(X_train, y_train, b=0, batch_size=64, history_length=1):\n",
    "    X_batch = np.zeros((batch_size, X_train.shape[1], X_train.shape[2], history_length))\n",
    "    for i in range(history_length):\n",
    "        X_batch[:,:,:,i] = X_train[i+b*batch_size:i+(b+1)*batch_size]\n",
    "    y_batch = y_train[history_length-1+b*batch_size:history_length-1+(b+1)*batch_size]\n",
    "    index = np.random.permutation(batch_size)\n",
    "    X_batch, y_batch = X_batch[index], y_batch[index]\n",
    "    return X_batch, y_batch\n",
    "\n",
    "X_batch, y_batch = sample_minibatch(X_valid, y_valid, b=0, batch_size=64, history_length=5)\n",
    "print(X_batch.shape)\n",
    "print(y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train[history_length-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSR37XwnX+a6xiGGrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12d460fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y_train_id = np.zeros(y_train.shape[0])\n",
    "for i in range(y_train.shape[0]):\n",
    "    y_train_id[i] = action_to_id(y_train[i])\n",
    "plt.hist(y_train_id)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "print(action_to_id(y_train[426]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[426]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(y_train[426], [0.0, 0.0, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_train_id == 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12d7b2978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# old version\n",
    "from __future__ import print_function\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import Model\n",
    "from utils import *\n",
    "from tensorboard_evaluation import Evaluation\n",
    "import tensorflow as tf\n",
    "\n",
    "def read_data(datasets_dir=\"./data\", frac = 0.1):\n",
    "    \"\"\"\n",
    "    This method reads the states and actions recorded in drive_manually.py \n",
    "    and splits it into training/ validation set.\n",
    "    \"\"\"\n",
    "    print(\"... read data\")\n",
    "    data_file = os.path.join(datasets_dir, 'data.pkl.gzip')\n",
    "  \n",
    "    f = gzip.open(data_file,'rb')\n",
    "    data = pickle.load(f)\n",
    "\n",
    "    # get images as features and actions as targets\n",
    "    X = np.array(data[\"state\"]).astype('float32')\n",
    "    y = np.array(data[\"action\"]).astype('float32')\n",
    "\n",
    "    # split data into training and validation set\n",
    "    n_samples = len(data[\"state\"])\n",
    "    X_train, y_train = X[:int((1-frac) * n_samples)], y[:int((1-frac) * n_samples)]\n",
    "    X_valid, y_valid = X[int((1-frac) * n_samples):], y[int((1-frac) * n_samples):]\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "\n",
    "def data_augmentation(X_train, y_train_id):\n",
    "    # left:\n",
    "    left_indices = (y_train_id == LEFT)\n",
    "    # right:\n",
    "    right_indices = (y_train_id == RIGHT)\n",
    "    X_new_left_data = np.flip(X_train[left_indices], axis=2)\n",
    "    X_new_right_data = np.flip(X_train[right_indices], axis=2)\n",
    "    y_new_left_data = np.zeros((X_new_left_data.shape[0])) + RIGHT\n",
    "    y_new_right_data = np.zeros((X_new_right_data.shape[0])) + LEFT\n",
    "    X_train_n = np.concatenate((X_train, X_new_left_data, X_new_right_data), axis=0)\n",
    "    y_train_id_n = np.concatenate((y_train_id, y_new_left_data, y_new_right_data), axis=0)\n",
    "    \n",
    "    return X_train_n, y_train_id_n\n",
    "\n",
    "def id_to_action(labels_id):\n",
    "    classes = 3\n",
    "    labels_action = np.zeros((labels_id.shape[0], classes))\n",
    "    labels_action[labels_id==LEFT] = [-1.0, 0.0, 0.0]\n",
    "    labels_action[labels_id==RIGHT] = [1.0, 0.0, 0.0]\n",
    "    labels_action[labels_id==STRAIGHT] = [0.0, 0.0, 0.0]\n",
    "    labels_action[labels_id==ACCELERATE] = [0.0, 1.0, 0.0]\n",
    "    labels_action[labels_id==BRAKE] = [0.0, 0.0, 0.2]\n",
    "    labels_action[labels_id==LEFT_BRAKE] = [-1.0, 0.0, 0.2]\n",
    "    labels_action[labels_id==RIGHT_BRAKE] = [1.0, 0.0, 0.2]\n",
    "    labels_action[labels_id==LEFT_ACCELERATE] = [-1.0, 1.0, 0.0]\n",
    "    labels_action[labels_id==RIGHT_ACCELERATE] = [1.0, 1.0, 0.0]\n",
    "    \n",
    "    return labels_action\n",
    "\n",
    "def uniform_sampling(X_train, y_train_id_n, num_samples):\n",
    "    n = X_train.shape[0]\n",
    "    weights = np.zeros(n)\n",
    "    left_indices = y_train_id_n == LEFT\n",
    "    weights[left_indices] = n / np.sum(left_indices)\n",
    "    right_indices = y_train_id_n == RIGHT\n",
    "    weights[right_indices] = n / np.sum(right_indices)\n",
    "    straight_indices = y_train_id_n == STRAIGHT\n",
    "    weights[straight_indices] = n / np.sum(straight_indices)\n",
    "    acce_indices = y_train_id_n == ACCELERATE\n",
    "    weights[acce_indices] = n / np.sum(acce_indices)\n",
    "    brake_indices = y_train_id_n == BRAKE\n",
    "    weights[brake_indices] = n / np.sum(brake_indices)\n",
    "    left_brake_indices = y_train_id_n == LEFT_BRAKE\n",
    "    weights[left_brake_indices] = n / np.sum(left_brake_indices)\n",
    "    right_brake_indices = y_train_id_n == RIGHT_BRAKE\n",
    "    weights[right_brake_indices] = n / np.sum(right_brake_indices)\n",
    "    left_acce_indices = y_train_id_n == LEFT_ACCELERATE\n",
    "    weights[left_acce_indices] = n / np.sum(left_acce_indices)\n",
    "    right_acce_indices = y_train_id_n == RIGHT_ACCELERATE\n",
    "    weights[right_acce_indices] = n / np.sum(right_acce_indices)\n",
    "    weights = weights / np.sum(weights)\n",
    "    samples_indices = np.random.choice(np.arange(n), num_samples, p = weights)\n",
    "    \n",
    "    return X_train[samples_indices], y_train_id_n[samples_indices]\n",
    "\n",
    "\n",
    "def sample_minibatch(X, y, b=0, batch_size=64, history_length=1):\n",
    "    # get small batch\n",
    "    X_batch = np.zeros((batch_size, X.shape[1], X.shape[2], history_length))\n",
    "    for i in range(history_length):\n",
    "        X_batch[:,:,:,i] = X[i+b*batch_size:i+(b+1)*batch_size]\n",
    "    y_batch = y[history_length-1+b*batch_size:history_length-1+(b+1)*batch_size]\n",
    "    # shuffle data slightly (because it's in the batch)\n",
    "    index = np.random.permutation(batch_size)\n",
    "    # X_batch, y_batch = X_train[b*batch_size:(b+1)*batch_size], y_train[b*batch_size:(b+1)*batch_size]\n",
    "    X_batch, y_batch = X_batch[index], y_batch[index]\n",
    "    return X_batch, y_batch\n",
    "\n",
    "\n",
    "def preprocessing(X_train, y_train, X_valid, y_valid, history_length=1):\n",
    "\n",
    "    # TODO: preprocess your data here.\n",
    "    # 1. convert the images in X_train/X_valid to gray scale. If you use rgb2gray() from utils.py, the output shape (96, 96, 1)\n",
    "    # 2. you can either train your model with continous actions (as you get them from read_data) using regression\n",
    "    #    or you discretize the action space using action_to_id() from utils.py. If you discretize them, you'll maybe find one_hot() \n",
    "    #    useful and you may want to return X_train_unhot ... as well.\n",
    "    X_train = rgb2gray(X_train)\n",
    "    X_valid = rgb2gray(X_valid)\n",
    "    # history:\n",
    "    n = X_train.shape[0]\n",
    "    # X_train_history = np.zeros((X_train.shape[0]-history_length+1, history_length, X_train.shape[1], X_train.shape[2]))\n",
    "    # for i in range(X_train_history.shape[0]):\n",
    "    #     X_train_history[i] = X_train[i:i+history_length,:,:]\n",
    "    # X_train_history = X_train_history.transpose(0,2,3,1)\n",
    "    \n",
    "    # X_valid_history = np.zeros((X_valid.shape[0]-history_length+1, history_length, X_valid.shape[1], X_valid.shape[2]))\n",
    "    # for i in range(X_valid_history.shape[0]):\n",
    "    #     X_valid_history[i] = X_valid[i:i+history_length,:,:]\n",
    "    # X_valid_history = X_valid_history.transpose(0,2,3,1)\n",
    "    \n",
    "    # y_valid_history = y_valid[history_length-1:]\n",
    "    # discretize actions\n",
    "    y_train_id = np.zeros(n)\n",
    "    # y_valid_id = np.zeros(y_valid.shape[0]-history_length+1)\n",
    "    \n",
    "    # data augmentation\n",
    "    for i in range(n):\n",
    "        y_train_id[i] = action_to_id(y_train[i])\n",
    " \n",
    "    # X_train_n, y_train_id_n = data_augmentation(X_train, y_train_id)\n",
    "    X_train_sampled, y_train_id_sampled = uniform_sampling(X_train, y_train_id, num_samples=20000)\n",
    "\n",
    "    y_train_action = id_to_action(y_train_id_sampled)\n",
    "    # History:\n",
    "    # At first you should only use the current image as input to your network to learn the next action. Then the input states\n",
    "    # have shape (96, 96,1). Later, add a history of the last N images to your state so that a state has shape (96, 96, N).\n",
    "    \n",
    "    # return X_train_sampled, y_train_action, X_valid_history, y_valid_history\n",
    "    return X_train_sampled, y_train_action, X_valid, y_valid\n",
    "\n",
    "\n",
    "def train_model(X_train, y_train, X_valid, y_valid, epochs, batch_size, lr, history_length=1, model_dir=\"./models\", tensorboard_dir=\"./tensorboard\"):\n",
    "    \n",
    "    # create result and model folders\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)  \n",
    " \n",
    "    print(\"... train model\")\n",
    "\n",
    "\n",
    "    # TODO: specify your neural network in model.py \n",
    "    agent = Model(learning_rate=lr, history_length=history_length)\n",
    "    init = tf.global_variables_initializer()\n",
    "    agent.sess.run(init)\n",
    "    tensorboard_eval = Evaluation(tensorboard_dir)\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # calculate the accuracy\n",
    "    # y_pred = tf.argmax(agent.output, 1)\n",
    "    # tf.add_to_collection('pred_network', y_pred)\n",
    "    # correct_pred = tf.equal(agent.y_pred, tf.argmax(agent.y_label, 1))\n",
    "    # calculate train and valid accuracy\n",
    "    # accuracy = tf.reduce_mean(tf.cast(correct_pred, \"float\"))\n",
    "    # init all variables\n",
    "    \n",
    "    # TODO: implement the training\n",
    "    # \n",
    "    # 1. write a method sample_minibatch and perform an update step\n",
    "    # 2. compute training/ validation accuracy and loss for the batch and visualize them with tensorboard. You can watch the progress of\n",
    "    #    your training in your web browser\n",
    "    \n",
    "    total_batch_num = (X_train.shape[0] - history_length + 1) // batch_size;\n",
    "    total_batch_num_valid = (X_valid.shape[0] - history_length + 1)// batch_size;\n",
    "    # training loop\n",
    "    train_cost = np.zeros((epochs))\n",
    "    # train_accuracy = np.zeros((epochs))\n",
    "    valid_cost = np.zeros((epochs))\n",
    "    for epoch in range(epochs):\n",
    "        # shuffle the data set\n",
    "        # index = np.random.permutation(X_train.shape[0])\n",
    "        # X_train, y_train = X_train[index], y_train[index]\n",
    "        # print(X_train.shape)\n",
    "        for b in range(total_batch_num):\n",
    "            # select the batch data\n",
    "            X_batch, y_batch = sample_minibatch(X_train, y_train, b, batch_size, history_length)\n",
    "            # compute the cost\n",
    "            _ , temp_cost = agent.sess.run([agent.optimizer, agent.cost], feed_dict={agent.x_input:X_batch, agent.y_label:y_batch})\n",
    "\n",
    "        # training cost\n",
    "        for b in range(total_batch_num):\n",
    "            X_batch, y_batch = sample_minibatch(X_train, y_train, b, batch_size, history_length)\n",
    "            train_cost[epoch] += agent.sess.run(agent.cost, feed_dict={agent.x_input: X_batch, agent.y_label: y_batch})\n",
    "\n",
    "        # validation cost\n",
    "        for b in range(total_batch_num_valid):\n",
    "            X_valid_batch, y_valid_batch = sample_minibatch(X_valid, y_valid, b, batch_size, history_length)\n",
    "            valid_cost[epoch] += agent.sess.run(agent.cost, feed_dict={agent.x_input:X_valid_batch, agent.y_label:y_valid_batch})\n",
    "        train_cost[epoch] = train_cost[epoch] / total_batch_num\n",
    "        valid_cost[epoch] = valid_cost[epoch] / total_batch_num_valid\n",
    "        print(\"[%d/%d]: train_cost: %.4f, valid_cost: %.4f\" %(epoch+1, epochs, train_cost[epoch], valid_cost[epoch]))\n",
    "        eval_dict = {\"train\":train_cost[epoch], \"valid\":valid_cost[epoch]}\n",
    "        tensorboard_eval.write_episode_data(epoch, eval_dict)\n",
    "      \n",
    "    # TODO: save your agent\n",
    "    agent.save(os.path.join(model_dir, \"agent.ckpt\"))\n",
    "    print(model_dir)\n",
    "    print(\"Model saved in file: %s\" % model_dir)\n",
    "    agent.sess.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_samples = 30000\n",
    "    # read data    \n",
    "    X_train, y_train, X_valid, y_valid = read_data(\"./data\")\n",
    "    X_train = X_train[:num_samples]\n",
    "    y_train = y_train[:num_samples]\n",
    "    history_length = 1\n",
    "    # preprocess data\n",
    "    X_train, y_train, X_valid, y_valid = preprocessing(X_train, y_train, X_valid, y_valid, history_length)\n",
    "    # train model (you can change the parameters!)\n",
    "    train_model(X_train, y_train, X_valid, y_valid, history_length=history_length, epochs=10, batch_size=64, lr=0.0004)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
