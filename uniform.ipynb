{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "uniform.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Pjyv7_C7kGeY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !pip install tensorboard\n",
        "# !pip install tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PtCaP02fcFy7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow==1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v-T6N-Ezj8x8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "np.set_printoptions(threshold=np.nan)\n",
        "import os\n",
        "import gzip\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "# from model import Model\n",
        "# from tensorboard_evaluation import Evaluation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HKhpLcjrkB5z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LEFT =1\n",
        "RIGHT = 2\n",
        "STRAIGHT = 0\n",
        "ACCELERATE =3\n",
        "BRAKE = 4\n",
        "\n",
        "def one_hot(labels):\n",
        "    \"\"\"\n",
        "    this creates a one hot encoding from a flat vector:\n",
        "    i.e. given y = [0,2,1]\n",
        "     it creates y_one_hot = [[1,0,0], [0,0,1], [0,1,0]]\n",
        "    \"\"\"\n",
        "    classes = np.unique(labels)\n",
        "    # n_classes = classes.size\n",
        "    n_classes = 5 # CHEAT\n",
        "\n",
        "    one_hot_labels = np.zeros(labels.shape + (n_classes,))\n",
        "    for c in classes:\n",
        "        one_hot_labels[labels == c, c] = 1.0\n",
        "    return one_hot_labels\n",
        "\n",
        "def rgb2gray(rgb):\n",
        "    \"\"\"\n",
        "    this method converts rgb images to grayscale.\n",
        "    \"\"\"\n",
        "    gray = np.dot(rgb[...,:3], [0.2125, 0.7154, 0.0721])\n",
        "    return gray.astype('float32')\n",
        "\n",
        "# TODO:::\n",
        "def action_to_id(a):\n",
        "    \"\"\"\n",
        "    this method discretizes the actions.\n",
        "    Important: this method only works if you recorded data pressing only one key at a time!\n",
        "    \"\"\"\n",
        "    if all(a == [-1.0, 0.0, 0.0]): return LEFT               # LEFT: 1\n",
        "    elif all(a == [1.0, 0.0, 0.0]): return RIGHT             # RIGHT: 2\n",
        "    elif all(a == [0.0, 1.0, 0.0]): return ACCELERATE        # ACCELERATE: 3\n",
        "    elif all(a == [0.0, 0.0, 0.2]): return BRAKE             # BRAKE: 4\n",
        "    elif all(a == [0.0, 0.0, 0.0]): return ACCELERATE if random.random() < 0.4 else STRAIGHT # TODO:::\n",
        "    else:\n",
        "        return STRAIGHT                                      # STRAIGHT = 0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s8e8LsZulYRH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oxMi7H8ymPZ0",
        "colab_type": "code",
        "outputId": "08580859-316c-41ec-c106-4fb422ca5c69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/data\""
      ],
      "execution_count": 521,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data.pkl.gzip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rNAJggjhkVJ_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_data(datasets_dir = \"./data\", frac = 0.1):\n",
        "    \"\"\"\n",
        "    This method reads the states and actions recorded in drive_manually.py\n",
        "    and splits it into training/ validation set.\n",
        "    \"\"\"\n",
        "    print(\"... read data\")\n",
        "    data_file = os.path.join(datasets_dir, 'data.pkl.gzip')\n",
        "\n",
        "    f = gzip.open(data_file,'rb')\n",
        "    data = pickle.load(f)\n",
        "\n",
        "    # get images as features and actions as targets\n",
        "    X = np.array(data[\"state\"]).astype('float32')\n",
        "    y = np.array(data[\"action\"]).astype('float32')\n",
        "\n",
        "    # split data into training and validation set\n",
        "    n_samples = len(data[\"state\"])\n",
        "    X_train, y_train = X[:int((1 - frac) * n_samples)], y[:int((1 - frac) * n_samples)]\n",
        "    X_valid, y_valid = X[int((1 - frac) * n_samples):], y[int((1 - frac) * n_samples):]\n",
        "\n",
        "    print(\"Size of:\")\n",
        "    print(\"- Training-set:\\t\\t{}\".format(X_train.shape[0])) # TODO:::\n",
        "    print(\"- Validation-set:\\t{}\".format(X_valid.shape[0])) # TODO:::\n",
        "\n",
        "    return X_train, y_train, X_valid, y_valid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EicFNERekalw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def shuffle_data(X, y):\n",
        "\n",
        "    zipped = np.array(list(zip(X ,y)))\n",
        "    np.random.shuffle(zipped)\n",
        "    X, y = zip(*zipped)\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    return X, y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VWOm4VXnkdQX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_it_hot(y, dtype = np.int8):\n",
        "\n",
        "    length = y.shape[0]\n",
        "    temp = np.zeros(length, dtype)\n",
        "\n",
        "    for i in range(length):\n",
        "        temp[i] = action_to_id(y[i])\n",
        "\n",
        "    return one_hot(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e9vU5sivkuJa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reshape_to_history_length(x, history_length):\n",
        "\n",
        "    batch_size   = x.shape[0]\n",
        "    image_width = x.shape[1]\n",
        "    image_height   = x.shape[2]\n",
        "        \n",
        "    temp = np.empty((batch_size - history_length + 1, image_width, image_height, history_length))\n",
        "    \n",
        "    for i in range(batch_size - history_length):\n",
        "        temp[i, :, :, :] = np.transpose(x[i: i + history_length, :, :, 0], (1, 2, 0))\n",
        "\n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mD44eM9dkw9Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def input_data_to_grayscale(X_train, X_valid):\n",
        "    # convert the images in X_train/X_valid to gray scale. If you use rgb2gray() from utils.py, the output shape (96, 96, 1)\n",
        "    return rgb2gray(X_train), rgb2gray(X_valid)\n",
        "\n",
        "def output_data_to_discrete(y_train, y_valid):\n",
        "    # you can either train your model with continous actions (as you get them from read_data) using regression\n",
        "    #    or you discretize the action space using action_to_id() from utils.py. If you discretize them, you'll maybe find one_hot()\n",
        "    #    useful and you may want to return X_train_unhot ... as well.\n",
        "    return make_it_hot(y_train), make_it_hot(y_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "glgmY9JBkzhX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def use_history(history_length, X_train, y_train, X_valid, y_valid):\n",
        "#     History:\n",
        "#     At first you should only use the current image as input to your network to learn the next action. Then the input states\n",
        "#     have shape (96, 96,1). Later, add a history of the last N images to your state so that a state has shape (96, 96, N).\n",
        "    \n",
        "    X_train = reshape_to_history_length(X_train, history_length)\n",
        "    y_train[history_length] = y_train[history_length - 1:]\n",
        "    X_valid = reshape_to_history_length(X_valid, history_length)\n",
        "    y_valid[history_length] = y_valid[history_length - 1:]\n",
        "\n",
        "    return X_train, y_train, X_valid, y_valid\n",
        "\n",
        "# def use_history(X, y, batch_index, history_length = 1):\n",
        "\n",
        "#     batch_size = batch_index.shape[0]\n",
        "#     X_batch = np.zeros((batch_size, X.shape[1], X.shape[2], history_length))\n",
        "#     for i in range(history_length):\n",
        "#         X_batch[:,:,:,i] = X[batch_index + i]\n",
        "#     y_batch = y[history_length - 1 + b * batch_size:history_length - 1 + (b + 1) * batch_size]\n",
        "    \n",
        "#     return X_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZJuake34k1ME",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocessing(X_train, y_train, X_valid, y_valid, history_length = 1, onehot = True):\n",
        "\n",
        "    print(\"... preprocessing data\")\n",
        "\n",
        "    X_train, X_valid = input_data_to_grayscale(X_train, X_valid)\n",
        "\n",
        "    if onehot:\n",
        "        y_train, y_valid = output_data_to_discrete(y_train, y_valid)\n",
        "\n",
        "    if history_length > 1:\n",
        "        X_train, y_train, X_valid, y_valid = use_history(history_length, X_train, y_train, X_valid, y_valid)\n",
        "\n",
        "    return X_train, y_train, X_valid, y_valid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FDMD0M57k3OY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_minibatch_indices(data_size, batch_size, history_length):\n",
        "\n",
        "    first_index = np.random.randint(0, data_size - batch_size - history_length - 1)\n",
        "    return first_index, (first_index + batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "elQ2AzV3k48r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reshape_input_data(x):\n",
        "    return np.reshape(x, (x.shape[0], 96, 96, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "brOMqyEwk7Nh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def count_output_data_hot_instances(y, j = ''):\n",
        "\n",
        "    counter_s = 0\n",
        "    counter_l = 0\n",
        "    counter_r = 0\n",
        "    counter_a = 0\n",
        "    counter_b = 0\n",
        "\n",
        "    for i in range(y.shape[0]):\n",
        "        if (y[i] == [1., 0., 0., 0., 0.]).all():\n",
        "            counter_s += 1\n",
        "        if (y[i] == [0., 1., 0., 0., 0.]).all():\n",
        "            counter_l += 1\n",
        "        if (y[i] == [0., 0., 1., 0., 0.]).all():\n",
        "            counter_r += 1\n",
        "        if (y[i] == [0., 0., 0., 1., 0.]).all():\n",
        "            counter_a += 1\n",
        "        if (y[i] == [0., 0., 0., 0., 1.]).all():\n",
        "            counter_b += 1\n",
        "\n",
        "    print(\"----- OUTPUT DATA -----\")\n",
        "    if (j != ''):\n",
        "        print(\"------- \", j, \"--------\")\n",
        "    print(\"STRAIGHT: \", counter_s)\n",
        "    print(\"LEFT: \", counter_l)\n",
        "    print(\"RIGHT: \", counter_r)\n",
        "    print(\"ACCELERATE: \", counter_a)\n",
        "    print(\"BRAKE: \", counter_b)\n",
        "    print(\"-----------------------\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o7FQXCLai4jG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def uniform_sampling(X, y, num_samples, history_length = 1, use_history = False):\n",
        "  \n",
        "  n = y.shape[0]\n",
        "  weights = np.zeros(n)\n",
        "  \n",
        "  straight = []\n",
        "  left = []\n",
        "  right = []\n",
        "  accelerate = []\n",
        "  brake = []\n",
        "  \n",
        "  for i in range(n):\n",
        "    if (y[i] == [1., 0., 0., 0., 0.]).all():\n",
        "      straight.append(i)\n",
        "    elif (y[i] == [0., 1., 0., 0., 0.]).all():\n",
        "      left.append(i)\n",
        "    elif (y[i] == [0., 0., 1., 0., 0.]).all():\n",
        "      right.append(i)\n",
        "    elif (y[i] == [0., 0., 0., 1., 0.]).all():\n",
        "      accelerate.append(i)\n",
        "    elif (y[i] == [0., 0., 0., 0., 1.]).all():\n",
        "      brake.append(i)\n",
        "  \n",
        "  straight_weight = n / len(straight) if (len(straight) != 0) else 1\n",
        "  left_weight = n / len(left) if (len(left) != 0) else 1\n",
        "  right_weight = n / len(right) if (len(right) != 0) else 1\n",
        "  accelerate_weight = n / len(accelerate) if (len(accelerate) != 0) else 1\n",
        "  brake_weight = n / len(brake) if (len(brake) != 0) else 1\n",
        "  \n",
        "  sum_weight = straight_weight + left_weight + right_weight + accelerate_weight + brake_weight\n",
        "  straight_weight /= sum_weight\n",
        "  left_weight /= sum_weight\n",
        "  right_weight /= sum_weight\n",
        "  accelerate_weight /= sum_weight\n",
        "  brake_weight /= sum_weight\n",
        "  \n",
        "#   print(\"straight weight: \", straight_weight)\n",
        "#   print(\"left weight: \", left_weight)\n",
        "#   print(\"right weight: \", right_weight)\n",
        "#   print(\"accelerate weight: \", accelerate_weight)\n",
        "#   print(\"brake weight: \", brake_weight)\n",
        "\n",
        "  weights[straight] = straight_weight\n",
        "  weights[left] = left_weight\n",
        "  weights[right] = right_weight\n",
        "  weights[accelerate] = accelerate_weight\n",
        "  weights[brake] = brake_weight\n",
        "\n",
        "  weights /= np.sum(weights)\n",
        "    \n",
        "  zipped = np.array(list(zip(X ,y)))\n",
        "    \n",
        "  chosen_indices = np.random.choice(np.arange(n), num_samples, replace = False, p = weights)\n",
        "  \n",
        "  if use_history:\n",
        "    chosen_indices = np.array([range(i - history_length, i, 1) for i in chosen_indices]).flatten() \n",
        "  \n",
        "  zipped = zipped[chosen_indices]\n",
        "      \n",
        "  X, y = zip(*zipped)\n",
        "\n",
        "  return np.array(X), np.array(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dcjc6pmqk9_f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(X_train, y_train,\n",
        "                X_valid, y_valid,\n",
        "                epochs, batch_size,\n",
        "                lr,\n",
        "                history_length = 1,\n",
        "                model_dir = \"./models\", tensorboard_dir = \"./tensorboard\"):\n",
        "\n",
        "    # create result and model folders\n",
        "    if not os.path.exists(model_dir):\n",
        "        os.mkdir(model_dir)\n",
        "        print(\"... folders created\")\n",
        "\n",
        "    when_to_show = 10\n",
        "\n",
        "    X_train = reshape_input_data(X_train)\n",
        "    X_valid = reshape_input_data(X_valid)\n",
        "    print(\"... input data reshaped\")\n",
        "\n",
        "#     agent = Model(batch_size = batch_size, history_length = history_length)\n",
        "#     print(\"... model created\")\n",
        "\n",
        "    # tensorboard_eval = Evaluation(tensorboard_dir)\n",
        "\n",
        "#     # Initialization\n",
        "#     agent.session.run(tf.global_variables_initializer())\n",
        "#     tf.reset_default_graph()\n",
        "#     print(\"... model initialized\")\n",
        "\n",
        "    training_accuracy = np.zeros((epochs))\n",
        "    #validation_cost = np.zeros((epochs))\n",
        "\n",
        "#     os.system('clear')\n",
        "    print(\"... train model\")\n",
        "    # training loop\n",
        "    for i in range(epochs):\n",
        "\n",
        "        first_index, last_index = get_minibatch_indices(X_train.shape[0], batch_size, history_length)\n",
        "\n",
        "        X_train_mini = X_train[first_index : last_index, :, :, :]\n",
        "        y_train_mini = y_train[first_index : last_index, :]\n",
        "\n",
        "#         feed_dict_train = {agent.x: X_train_mini, agent.y_true: y_train_mini}\n",
        "#         agent.session.run(agent.optimizer, feed_dict=feed_dict_train)\n",
        "\n",
        "        if i % when_to_show == 0:\n",
        "            # Calculate the accuracy on the training-set.\n",
        "#             training_accuracy[i] += agent.session.run(agent.accuracy, feed_dict=feed_dict_train)\n",
        "\n",
        "            # Message for printing.\n",
        "#             msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
        "\n",
        "            # Print it.\n",
        "#             print(msg.format(i + 1, training_accuracy[i]))\n",
        "            count_output_data_hot_instances(y_train_mini, i)\n",
        "\n",
        "        # compute training/ validation accuracy and loss for the batch and visualize them with tensorboard. You can watch the progress of\n",
        "        #    your training in your web browser\n",
        "            \n",
        "        # eval_dict = {\"train\":training_cost[i], \"valid\":validation_cost[i]}\n",
        "        # tensorboard_eval.write_episode_data(i, eval_dict)\n",
        "\n",
        "    # save your agent\n",
        "#     save_path = os.path.join(model_dir, \"agent.ckpt\")\n",
        "#     agent.save(save_path)\n",
        "#     print(\"... model saved in file: %s\" % save_path)\n",
        "#     agent.session.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0SivXYEOk_0I",
        "colab_type": "code",
        "outputId": "a04a12e8-2628-429e-85e7-bdd32ad40f9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        }
      },
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    history_length = 2\n",
        "    use_h = True\n",
        "\n",
        "    # read data\n",
        "    X_train, y_train, X_valid, y_valid = read_data(\"/content/drive/My Drive/data\")\n",
        "    print(\"... data read\")\n",
        "    \n",
        "    offset = int(X_train.shape[0] / 3)\n",
        "\n",
        "    if not use_history:\n",
        "      X_train, y_train = shuffle_data(X_train, y_train)\n",
        "      X_valid, y_valid = shuffle_data(X_valid, y_valid)\n",
        "      print(\"... data shuffled\")\n",
        "\n",
        "    # preprocess data\n",
        "    X_train, y_train_hot, X_valid, y_valid_hot = preprocessing(X_train, y_train, X_valid, y_valid, history_length = history_length)\n",
        "    print(\"... data preprocessed\")\n",
        "    \n",
        "    X_train, y_train_hot = uniform_sampling(X_train, y_train_hot, offset, history_length, use_history = use_h)\n",
        "       \n",
        "    count_output_data_hot_instances(y_train_hot)\n",
        "   "
      ],
      "execution_count": 534,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "... read data\n",
            "Size of:\n",
            "- Training-set:\t\t4500\n",
            "- Validation-set:\t500\n",
            "... data read\n",
            "... preprocessing data\n",
            "x:  (4500, 96, 96)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-534-44bb54740f37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# preprocess data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"... data preprocessed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-528-9cd3b3764c60>\u001b[0m in \u001b[0;36mpreprocessing\u001b[0;34m(X_train, y_train, X_valid, y_valid, history_length, onehot)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhistory_length\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-527-9aea530ec129>\u001b[0m in \u001b[0;36muse_history\u001b[0;34m(history_length, X_train, y_train, X_valid, y_valid)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     have shape (96, 96,1). Later, add a history of the last N images to your state so that a state has shape (96, 96, N).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape_to_history_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhistory_length\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhistory_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mX_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape_to_history_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-525-d7f0e38ac1e8>\u001b[0m in \u001b[0;36mreshape_to_history_length\u001b[0;34m(x, history_length)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mhistory_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhistory_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ofaR-iLtrzAw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " train_model(X_train, y_train_hot,\n",
        "                X_valid, y_valid_hot,\n",
        "                history_length = history_length,\n",
        "                epochs = 100, batch_size = 64, lr = 0.0004)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}